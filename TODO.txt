*Asymob: A framework for SYsteMatic testing Of chatBots 
==================================================================================================
DONE.

*Vaciar el proyecto bowling
*Incluir los operadores:
  -deleteChars
  -traductionChained
  -randomTraductionChained
  -changeWordToNumber
  -activeToPassive (DONE 08/01/21)
  -convertAdjectivesToSynonyms (DONE 04/01/21)
  -convertAdjectivesToAntonyms (DONE 04/01/21)
  -convertObjectsToSynonyms (DONE 28/12/20)
  -convertAdverbsToSynonyms (DONE 28/12/20)
  -convertAdverbsToAntonyms (DONE 28/12/20)
  
 *Analizar como asociar cada tipo de operador de mutacion. (DONE 18/12/20)
   - Poder encajar el operador de mutacion y su cfg, a su implementacion.
   - Para permitir asi incluir, operadores de mutacion con implementaciones distintas.
     · MutUtterance: desde java + desde python1 + desde python2
   
   
*Adaptar el .py para que pueda gestionar los operadores correctamente, no hardcoded. (DONE 11/12/20)

*Elegir la estructura de codigo, para que encajen correctamente los operadores de mut.  (DONE 15/12/20)

*Problema con wordnet: escribe en linea de comandos, pese a redireccionar la salida en linux (DONE 29/12/20)

*Inclusion nuevo sistema de traduccion, apertium. Hay un problema, depende del flujo de traduccion, traduce mejor o peor. No puede ser generico (DONE 05/01/21)

*Inclusion de conversion de frases en pasiva a activa, utilizando 'spacy' (DONE 08/01/21)

*Crear un nuevo proyecto (DONE 08/01/21)

*Empaquetar el codigo en modo api y dejar funciones completas. (DONE 08/01/21)

*Gestionar las frases compuestas, que tienen mezcla de Literal y ParameterReferenceToken. (DONE 18/01/21)

* Terminar test cases. Se complica con la generacion de las frases compuestas, unidas a los distintos parametros que han podido generarse con los operadores de mutacion

* Hacer un operador en java, para dejarlo como basico. (creo que nos seria de valor re-hacer el de los sinonimos y antonimos) (DONE 08/02/21)
==================================================================================================
PENDING.
* Mejorar botium export [https://floriantreml.medium.com/botium-in-a-nutshell-part-2-writing-chatbot-tests-8726204c8da6]

*Exportacion a Dialogflow.

*Funcionamiento correcto de max y min

*Gestion de frases de entrenamiento: una vez procesadas, poder extraerlas en texto plano (por intent id ó todas), o aplicarlas al bot

*Comentar codigo

*Mejora entities

*Diagrama de clases, para visualizar los componentes del sistema y su interacción.

*Hay un lio bastante grande con los nombres (el funcionamiento esta bien) del package training. Además, estaría bien saber que operadores han sido
los artifices de la generación de cada frase. Pair<EMutationOperator, String>

*Gestión de los actions con HTTPRequest y response

*Chequeo core botium.

*Incluir la deteccion de que la gramatica de las respuestas, y sobre todo de las output (a veces se forman mal)
==================================================================================================
Posibles nuevos operadores:
* Intercambio de simbolos de interrogación, a exclamacion.
* Eliminación de tildes de manera aleatoria. 
* Eliminar algun tag? Podemos tener bots muy centrados en sus tags
* Incluir un required de más?
* Cambiar una palabra por su antónimo, y ver si cambia el tono de la frase

*Parónimos, homónimos, meronimos, hipónimos.
*Mejora de entidades: utilizar hipónimos para incrementar el conjunto de instancia de la entidad, y generar sinónimos de cada uno de ellos (Contracciones) 
*Mejora de parámetros: Reescribir los prompts

==================================================================================================
Testing NLP-Intense chatbots
[https://livablesoftware.com/testing-challenges-for-nlp-intensive-bots/]
Tipos de testing:
Metamorphic: potential_mrs
Unit test: Botium
Performance: Medir el rendimiento. Podemos hacerlo con rasa
Back-to-back testing: could be used to test the bot quality when using different NLP engines or configurations. 
[For example, a bot deployed over DialogFlow may work better/worse than the same bot deployed over IBM Watson.]

Security testing...
Conformance: Que si el chatbot trata de algo, que sepa contestar. O si dice que es en ingles, que las frases sean en ingles.

*Cobertura
 -Ya que partimos de una cobertura total. Probar a hacer test suite prioritization (tratar de reducir el tamaño de training phrases muy parecidas, incluso de arreglar el CNF alto)
 -Cobertura de entidades?

*Operadores de mutacion de estructura de chatbots? 
INTENTS:
* Cambiar las frases de entrenamiento de intent por otro.
* Reescribir las frases en negativo, o con el verbo contrario.
* Cambiar el idioma de la training phrase?
* Eliminar las training phrases de un intent
* Anyadir un nuevo lenguaje, cambiar el lenguaje y traducir esas frases en ese lenguaje 

PARAMETERS:
* Cambiar un parámetro de entidad 
* Cambiar el prompt de un parámetro 
* Cambiar un tipo por @any

ENTITIES:
* Cambiar una entidad de tipo.
* Insertar en lugar de sinonimos, antonimos
* Eliminar todos los Literales menos 1

FLOWS:
* Cambiar un flow (apuntando a otro intent)
* Swap flow: intercambiar el intent de orden si el CL es suficientemente grande

==================================================================================================
Ideas:
Bot de discord.

*[Si] Medición de cohesion, separation and confusing phrases. []
  -> Tensorflow y universal sentence encoding [https://www.javacodegeeks.com/2019/07/similarity-using-universal-sentence-encoder.html]
     · https://github.com/awslabs/djl/blob/master/examples/src/main/java/ai/djl/examples/inference/UniversalSentenceEncoder.java
*Medicion de intentDetectionConfidence: https://stackoverflow.com/questions/48039722/how-to-determine-confidence-level-in-dialogflow/56122074#56122074
   
*[Si] Caracteristicas del texto: text statistics (number of words per sentence), sentiment analysis, readability metrics (Flesch-Reading-Ease)

*[No] Anotación automática de frases con coreNLP y uso de entidades?

* Testing de entidades y de expresiones regulares.   

* Utilizar BLEU para generar traducciones buenas en la generación de testcases

*Comprobacion de que se cumplen los idiomas propuestos.

*Capturar las excepciones de stanford tokenizer

*Capturar las excepciones de heap java error
==================================================================================================
CORENLP (OpenSource)(https://corenlp.run/)
WORDNET (OpenSource)(http://wordnetweb.princeton.edu/perl/webwn)
LANGUAGE TOOL (OpenSource)(https://languagetool.org/)

NLP Sentence Encoder: Similarity(https://jinglescode.github.io/demos/nlp-sentence-encoder)
WS4J (OpenSource)(https://ws4jdemo.appspot.com/) Similarity
Deep Java Library (OpenSource)(https://djl.ai/)
Quillbot (privado)(https://quillbot.com/)
 · Reescritura de frases
FastText (OpenSource)(https://fasttext.cc/) -> Es una biblioteca para el aprendizaje de incrustaciones de palabras y clasificación de texto creada por el laboratorio de investigación de inteligencia artificial de Facebook.
 · Etiquetado de frases.

RAT (https://github.com/MatthiasHoldorf/readability-analysis-tool)
Python textstat (https://github.com/shivam5992/textstat) 
//Check if a word is recognised
SentimentModel model = SentimentModel.loadSerialized("edu/stanford/nlp/models/sentiment/sentiment.ser.gz");
boolean knownWord = model.wordVectors.containsKey("foo");